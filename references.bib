@inproceedings{metaschedule,
author       = {Junru Shao and
                Xiyou Zhou and
                Siyuan Feng and
                Bohan Hou and
                Ruihang Lai and
                Hongyi Jin and
                Wuwei Lin and
                Masahiro Masuda and
                Cody Hao Yu and
                Tianqi Chen},
editor       = {Sanmi Koyejo and
                S. Mohamed and
                A. Agarwal and
                Danielle Belgrave and
                K. Cho and
                A. Oh},
title        = {Tensor Program Optimization with Probabilistic Programs},
booktitle    = {Advances in Neural Information Processing Systems 35: Annual Conference
                on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans,
                LA, USA, November 28 - December 9, 2022},
year         = {2022},
timestamp    = {Mon, 08 Jan 2024 16:31:36 +0100},
}
@inproceedings {tvm,
author = {Tianqi Chen and Thierry Moreau and Ziheng Jiang and Lianmin Zheng and Eddie Yan and Haichen Shen and Meghan Cowan and Leyuan Wang and Yuwei Hu and Luis Ceze and Carlos Guestrin and Arvind Krishnamurthy},
title = {{TVM}: An Automated {End-to-End} Optimizing Compiler for Deep Learning},
booktitle = {13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18)},
year = {2018},
isbn = {978-1-939133-08-3},
address = {Carlsbad, CA},
pages = {578--594},
publisher = {USENIX Association},
month = oct
}
@inbook{pytorch,
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and K\"{o}pf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
title = {PyTorch: an imperative style, high-performance deep learning library},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs.In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {721},
numpages = {12}
}
@inproceedings{torchvision,
author = {Marcel, S\'{e}bastien and Rodriguez, Yann},
title = {Torchvision the machine-vision package of torch},
year = {2010},
isbn = {9781605589336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {This paper presents Torchvision an open source machine vision package for Torch. Torch is a machine learning library providing a series of the state-of-the-art algorithms such as Neural Networks, Support Vector Machines, Gaussian Mixture Models, Hidden Markov Models and many others. Torchvision provides additional functionalities to manipulate and process images with standard image processing algorithms. Hence, the resulting images can be used directly with the Torch machine learning algorithms as Torchvision is fully integrated with Torch. Both Torch and Torchvision are written in C++ language and are publicly available under the Free-BSD License.},
booktitle = {Proceedings of the 18th ACM International Conference on Multimedia},
pages = {1485â€“1488},
numpages = {4},
keywords = {vision, pattern recognition, open source, machine learning, face detection and recognition},
location = {Firenze, Italy},
series = {MM '10}
}
@article{EfficientNet,
  author       = {Mingxing Tan and
                  Quoc V. Le},
  title        = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
  journal      = {CoRR},
  volume       = {abs/1905.11946},
  year         = {2019},
  eprinttype    = {arXiv},
  eprint       = {1905.11946},
  timestamp    = {Mon, 03 Jun 2019 13:42:33 +0200},
}
@article{MobileNet,
author       = {Andrew G. Howard and
                Menglong Zhu and
                Bo Chen and
                Dmitry Kalenichenko and
                Weijun Wang and
                Tobias Weyand and
                Marco Andreetto and
                Hartwig Adam},
title        = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
                Applications},
journal      = {CoRR},
volume       = {abs/1704.04861},
year         = {2017},
eprinttype    = {arXiv},
eprint       = {1704.04861},
timestamp    = {Thu, 27 May 2021 16:20:51 +0200},
}
@ARTICLE{EdgeTPU,
author={Cass, Stephen},
journal={IEEE Spectrum}, 
title={Taking AI to the edge: Google's TPU now comes in a maker-friendly package}, 
year={2019},
volume={56},
number={5},
pages={16-17},
keywords={},
doi={10.1109/MSPEC.2019.8701189}
}
@misc{orinnano,
title = {NVIDIA Jetson Orin Nano Developer Kit},
url = {https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/},
author = {NVIDIA},
year = {2023},
note = {Accessed on 4 12, 2024}
}
@misc{onnxruntime,
title = {Microsoft ONNX Runtime},
url = {https://onnxruntime.ai/},
author = {Microsoft},
year = {2019},
note = {Accessed on 4 12, 2024}
}
